{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Data Progrmming - Assignment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import us\n",
    "from mpl_toolkits.basemap import Basemap #conda install basemap if not installed. Also, conda install pillow for Python 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "URL1 = \"https://earthquake.usgs.gov/fdsnws/event/1/query?\"\n",
    "URL2 = \"https://earthquake.usgs.gov/fdsnws/event/1/count?\"\n",
    "\n",
    "PARAMETERS1 = { \"format\": 'csv', \"starttime\": '2016-01-01', \"endtime\": '2017-01-01', \"minmagnitude\": 4.0}\n",
    "PARAMETERS2 = { \"format\": 'csv', \"starttime\": '2017-01-01', \"endtime\": '2018-01-01', \"minmagnitude\": 4.0}\n",
    "PARAMETERS3 = { \"format\": 'csv', \"starttime\": '2018-01-01', \"endtime\": '2019-01-01', \"minmagnitude\": 4.0}\n",
    "PARAMETERS4 = { \"format\": 'csv', \"starttime\": '2019-01-01', \"endtime\": '2019-10-02', \"minmagnitude\": 4.0}\n",
    "\n",
    "c1 = int(requests.get(url = URL2, params = PARAMETERS1).text)\n",
    "c2 = int(requests.get(url = URL2, params = PARAMETERS2).text)\n",
    "c3 = int(requests.get(url = URL2, params = PARAMETERS3).text)\n",
    "c4 = int(requests.get(url = URL2, params = PARAMETERS4).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "r1 = requests.get(url = URL1, params = PARAMETERS1).text\n",
    "r2 = requests.get(url = URL1, params = PARAMETERS2).text\n",
    "r3 = requests.get(url = URL1, params = PARAMETERS3).text\n",
    "r4 = requests.get(url = URL1, params = PARAMETERS4).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = r1 + r2 + r3 + r4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.txt\", \"w\") as output:\n",
    "    output.write(str(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.txt\", sep=\",\", encoding ='latin1')\n",
    "data = data[data.latitude !='latitude'] #Removing the rows having coulmn names as an entry\n",
    "data = data[data.type == 'earthquake'] #Removing non-earthquake entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use describe to get the basic statistics of all the columns (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the top 10 earthquakes by magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['mag'] =pd.to_numeric(data['mag'])\n",
    "data.nlargest(10, columns = ['mag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle all Null/empty data by filling it with zeros (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.fillna(0)\n",
    "df\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the top 10 places where the strongest earthquakes occurred (15 points) (Note: Place needs to be parsed nicely to remove the KM location from them. For example: 75km WSW of Illapel, Chile should look like Illapel, Chile)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4 = df.nlargest(15, columns = ['mag'])\n",
    "q4['Place'] = q4['place'].str.split('of').str[1]\n",
    "q4.groupby(['Place',], sort=False)['mag'].max().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the top 10 places where the weakest earthquakes occurred (15 points) (Note: Place needs to be parsed nicely to remove the KM location from them. For example: 75km WSW of Illapel, Chile should look like Illapel, Chile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q5 = df.nsmallest(15, columns = ['mag'])\n",
    "q5['Place'] = q5['place'].str.split('of').str[1]\n",
    "q5.groupby(['Place'], sort=False)['mag'].max().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### On a per-year basis, use a bar chart to plot the number of earthquakes for each of the following magnitude groups ranges: Group 1: [4,4.5), Group 2: [4.5,5), Group 3: [5,6), Group 4: [6,7), Group 5:(7,MAX]. Pay close attention to the group ranges. (20 points) Please add labels and colors to the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q6 = df[df.mag != 7.0 ] #Removing earthquakes with magnitude 7 as they are not needed\n",
    "q6['time'] = pd.to_datetime(q6.time)\n",
    "q6['Year'] = q6['time'].dt.year\n",
    "q6['Group'] = pd.cut(q6['mag'], bins=[4,4.5,5,6,7,9],right=False, include_lowest = True, labels=[\"Group 1\", \"Group 2\", \"Group 3\", \"Group 4\", \"Group 5\"])\n",
    "\n",
    "plt.figure()\n",
    "plt.suptitle('Year VS Earthquake count for every group')\n",
    "plt.subplots_adjust(hspace=1, wspace=1)\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(\"Year 2016\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Group\")\n",
    "q6_2016 = q6[q6.Year == 2016]\n",
    "q6_2016.Group.value_counts().plot(kind='barh',color='aqua')\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title(\"Year 2017\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Group\")\n",
    "q6_2017 = q6[q6.Year == 2017]\n",
    "q6_2017.Group.value_counts().plot(kind='barh', color = 'coral')\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title(\"Year 2018\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Group\")\n",
    "q6_2018 = q6[q6.Year == 2018]\n",
    "q6_2018.Group.value_counts().plot(kind='barh', color = 'orchid')\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title(\"Year 2019\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Group\")\n",
    "q6_2019 = q6[q6.Year == 2019]\n",
    "q6_2019.Group.value_counts().plot(kind='barh', color = 'yellowgreen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find the 10 countries with the highest number of earthquakes (30 points) (Note: Yes, this is only countries, not full place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q7 = df.copy()\n",
    "def my_function(item1):\n",
    "    item = str(item1)\n",
    "    if(',' in item):\n",
    "        item = item.split(', ')[1]\n",
    "    elif('of' in item):\n",
    "        item = item.split('of ')[1]\n",
    "    else:\n",
    "        item = item1\n",
    "    return item\n",
    "\n",
    "q7['Country'] = q6.place.apply(lambda x: my_function(x))\n",
    "q7.groupby(q7.Country).size().nlargest(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analyze the distribution of the Earthquake magnitudes. This is, make a histogram of the Earthquake count versus magnitude. Make sure to use a Logarithmic scale. What sort of relationship do you see? (20 points) Please add labels and colors to the plot.\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Earthquake count(log) VS Magnitude\")\n",
    "plt.xlabel(\"Magnitude\")\n",
    "plt.ylabel(\"Count(log)\")\n",
    "plt.hist(df.mag, log=True, color = 'violet');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: A strong negative correlation between the log(number of earthquakes) and the magnitude. As the magnitude is increasing, the number of earthquakes is decreasing. Being a logarithmic scale, the decay is exponential. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analyze the distribution of the Earthquake depths. This is, make a histogram of the Earthquake count versus depth. Make sure to use a Logarithmic scale. What sort of relationship do you see? (20 points) Please add labels and colors to the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['depth'] = pd.to_numeric(df['depth'])\n",
    "plt.title(\"Earthquake count(log) VS Depth\")\n",
    "plt.xlabel(\"Depth(Km)\")\n",
    "plt.ylabel(\"Count(log)\")\n",
    "plt.hist(df.depth,bins=10, color='green')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: A lot number of earthquakes originate from 0-70Km depth. The count decreases as we move deeper into earth's core till approx 270Km. Now, the earthquake surprisingly remains constant till 490Km. Between 490-610Km, the count increases rapidly and then drop till 700Km. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize the locations of earthquakes by making a scatterplot of their latitude and longitude. (20 points) Please add labels and colors to the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['latitude'] = pd.to_numeric(df['latitude'])\n",
    "df['longitude'] = pd.to_numeric(df['longitude'])\n",
    "plt.title(\"Scatter plot of Earthquakes by Longitude and Latitude\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.scatter(df.longitude, df.latitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using the US package (https://pypi.org/project/us/), clean the dataset you used previously to only have data from the USA . You need to create a function that accommodates this. (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USA = [str(item) for item in us.STATES] #Considering only US states. Not all governing territories\n",
    "q11 = df.copy()\n",
    "def checkUSA(place, USA = USA):\n",
    "    a = ''\n",
    "    for item in USA:\n",
    "        if item.lower() in place.lower():\n",
    "            a = item\n",
    "    return(a)\n",
    "q11['State'] = q11.place.apply(lambda x: checkUSA(x, USA))\n",
    "q11['State'].value_counts()\n",
    "q11USA = q11[q11.State != '']\n",
    "\n",
    "#Removing Earthquakes from 'South Georgia and the South Sandwich Islands' which were considered as Georgia state, USA\n",
    "def georgia(item1):\n",
    "    item = str(item1)\n",
    "    if('South Georgia and the South Sandwich Islands' in item):\n",
    "        item = 'Drop'\n",
    "    if('South Georgia Island region' in item):\n",
    "        item ='Drop'\n",
    "    return item\n",
    "q11USA['Drop'] = q11USA.place.apply(lambda x: georgia(x))\n",
    "usDATA = q11USA[q11USA.Drop != 'Drop']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find the top 10 US states where the strongest earthquakes occurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q11largest = usDATA.nlargest(300, columns = ['mag'])\n",
    "q11largest.groupby(['State'], sort=False)['mag'].max().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### On a per-year basis, use a bar chart to plot the number of earthquakes for each of the following magnitude groups ranges: Group 1: [4,4.5), Group 2: [4.5,5), Group 3: [5,6), Group 4: [6,7), Group 5: (7,MAX]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q12USA = usDATA[usDATA.mag != 7.0 ] #Removing all entries which has earthquake magnitude = 7\n",
    "q12USA['time'] = pd.to_datetime(q12USA.time)\n",
    "q12USA['Year'] = q12USA['time'].dt.year\n",
    "q12USA['Group'] = pd.cut(q12USA['mag'], bins=[4,4.5,5,6,7,9],right=False, include_lowest = True, labels=[\"Group 1\", \"Group 2\", \"Group 3\", \"Group 4\", \"Group 5\"])\n",
    "\n",
    "plt.figure()\n",
    "plt.suptitle('Year VS Earthquake count for every group in United States of America')\n",
    "plt.subplots_adjust(hspace=1, wspace=1)\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(\"Year 2016\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Group\")\n",
    "q12USA_2016 = q12USA[q12USA.Year == 2016]\n",
    "q12USA_2016.Group.value_counts().plot(kind='barh',color='aqua')\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title(\"Year 2017\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Group\")\n",
    "q12USA_2017 = q12USA[q12USA.Year == 2017]\n",
    "q12USA_2017.Group.value_counts().plot(kind='barh', color = 'coral')\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title(\"Year 2018\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Group\")\n",
    "q12USA_2018 = q12USA[q12USA.Year == 2018]\n",
    "q12USA_2018.Group.value_counts().plot(kind='barh', color = 'orchid')\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title(\"Year 2019\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Group\")\n",
    "q12USA_2019 = q12USA[q12USA.Year == 2019]\n",
    "q12USA_2019.Group.value_counts().plot(kind='barh', color = 'yellowgreen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize the locations of earthquakes by making a scatterplot of their latitude and longitude. Overlay a US map on top of this plot to match the locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usDATA['latitude'] = pd.to_numeric(usDATA['latitude'])\n",
    "usDATA['longitude'] = pd.to_numeric(usDATA['longitude'])\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 8)\n",
    "m = Basemap(projection='merc', \\\n",
    "            llcrnrlat=14, urcrnrlat=66, \\\n",
    "            llcrnrlon=-163, urcrnrlon=-50, \\\n",
    "            lat_ts=20, \\\n",
    "            resolution='c')\n",
    "latitude = usDATA[\"latitude\"].tolist()\n",
    "longitude = usDATA[\"longitude\"].tolist()\n",
    "\n",
    "m.bluemarble(scale=0.5)\n",
    "m.drawcoastlines(color='white', linewidth=0.2)\n",
    "plt.title('Earthquakes in USA from 2016 to October 1, 2019')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "x, y = m(longitude, latitude)\n",
    "plt.scatter(x, y, 10, marker='x', color='yellow') \n",
    "plt.show()\n",
    "\n",
    "#Source: https://jakevdp.github.io/PythonDataScienceHandbook/04.13-geographic-data-with-basemap.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
